{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion Sort\n",
    "\n",
    "Source: [CS 161 Lecture 1](http://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture1.pdf)\n",
    "\n",
    "Insertion sort is an algorithm for sorting arrays. The following figure shows how insertion sort works. The whole time, you have a \"sorted\" part of the array (on the left) and an \"unsorted\" part of the array (on the right). In the beginning, the entire array is unsorted, and the sorted part of the array is just the first element in the array. On each iteration of the outer loop, you extend the sorted part by one element, and move that element to the correct position in the sorted part of the array. Eventually all of the numbers end up in the sorted part and the array is sorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions\n",
    "\n",
    "In order to meaningfully analyze algorithms, we first need to formalize exactly how they work. When doing this we abstract away implementation details that are specific to a particular computer architecture, or a particular programming language. Instead, we make mathematical assumptions about the behavious of computers and base all our analyses on these assumptions. As a result, analyzing algorithms become more about proving theorems than actual programming.\n",
    "\n",
    "For example, we assum that it takes constant time to access any element in an array. This is not necessarily true in practice, since computers have caches, and the time required to access an element on a real computer depends on which previous elements have been accessed. However, the constant time assumption is mathematically convenient for our purposes.\n",
    "\n",
    "In this class, we will use the \"RAM model\" of computation unless otherwise specified. This model assumes that the following instructions take constant time: (this list of instructions is from page 23 of CLRS)\n",
    "\n",
    "- Arithmetic: add, subtract, multiply, divide, remainder, floor, ceiling\n",
    "- Data movement: load, store, copy\n",
    "- Flow control: conditional and unconditional branch, subroutine call, return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formal description of insertion sort\n",
    "\n",
    "- Input: A sequence of _n_ numbers (a1, a2, ... , an)\n",
    "- Output: A permutation of those numbers (a'1, a'2, ... a'n) where a'1 <= a'2 <= ... <= a'n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\t[5, 2, 4, 6, 1, 3]\n",
      "After\t[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "a = [5, 2, 4, 6, 1, 3]\n",
    "\n",
    "print(f'Before\\t{a}')\n",
    "\n",
    "for j in range(1, len(a)):\n",
    "    key = a[j]\n",
    "    # Insert a[j] into the sorted sequence a[1..j-1]\n",
    "    i = j - 1\n",
    "    while i >= 0 and a[i] > key:\n",
    "        a[i+1] = a[i]\n",
    "        i = i - 1\n",
    "    a[i+1] = key\n",
    "    \n",
    "print(f'After\\t{a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of correctness\n",
    "\n",
    "In analyzing algorithms, it is important that they do what we say they do (i.e. given an input that meets the specifications, the algorithm produces the specified output). It's so important than often we find ourselves writing proofs that the algorithms are correct. Many of the standard proof techniques apply here, such as __proof by contradiction__ and __proof by induction__.\n",
    "\n",
    "To prove insertion sort is corect, we will use __\"loop invariants.\"__ The loop invariant we'll use is\n",
    "\n",
    "__Lemma:__ At the start of __each__ iteration of the for loop, the subarray A[1..j-1] consists of the elements originally in A[1..j-1], but in sorted order.\n",
    "\n",
    "To use this, we need to prove three conditions:\n",
    "\n",
    "__Initialization:__ The loop invariant is __satisfied__ at the beginning of the for loop.\n",
    "\n",
    "__Maintenance:__ If the loop invariant is true before the _i_-th iteration, then the loop invariant will be true before the _i_ + 1st iteration.\n",
    "\n",
    "__Termination:__ When the loop terminates, the invariant gives us a useful property that helps show that the algorithm is correct.\n",
    "\n",
    "Note that this is basically mathematical induction (the initialization is the base case, and the maintenance is the inductive step).\n",
    "\n",
    "In the case of insertion sort, we have:\n",
    "\n",
    "__Initialization:__ Before the first iteration (which is when _j_ = 2), the subarray [1..j-1] is just the first element of the array, A[1]. This __subarray is sorted__, and consists of the elements that were originally in A[1..1].\n",
    "\n",
    "__Maintenance:__ Suppose A[1..j-1] is sorted. Informally, the body of the loop works by moving A[j-1], A[j-2], A[j-3] and so on by one position to the right until it finds the proper position for A[j] (lines 4-7), at which point it inserts the value of A[j] (line 8). The subarray A[1..j] then consists of the elements originally in A[1..j], but in sorted order. Incrementing _j_ for the next iteration of the for loop then preserves the loop invariant.\n",
    "\n",
    "__Termination:__ The condition causing the for loop to terminate is that _j_ > _n_. Because each loop iteration increases _j_ by 1, we must have _j_ = _n_ + 1 at that time. By the initialization and maintenance steps, we have shown that the subarray A[1..n + 1 - 1] consists of the elements originally in A[1..n], but in sorted order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime analysis\n",
    "\n",
    "#### Running time\n",
    "\n",
    "The running time of an algorithm on a particular input is the __number of primitive operations_ or \"steps\" executed__. We __assume that a constant amount of time is required to execute each line of our pseudocode__. One line may take a different amount of time than another line, but we shall assume that each execution of the _i_-th line takes time c_i, where c_i is a constant.\n",
    "\n",
    "Let t_j represent the number of times the while loop test is executed on the _j_-th iteration of the for loop. Then the total runtime is (see figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [5, 2, 4, 6, 1, 3]\n",
      "After: [1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "a = [5, 2, 4, 6, 1, 3]\n",
    "\n",
    "print(f'Before: {a}')\n",
    "                                          # cost * times\n",
    "for j in range(1, len(a)):                # c1 * n\n",
    "    key = a[j]                            # c2 * (n - 1)\n",
    "    # Insert a[j] into the...\n",
    "    # ...sorted sequence a[1..j-1]        # 0  (n - 1)\n",
    "    i = j - 1                             # c4 * (n - 1)\n",
    "    while i >= 0 and a[i] > key:          # c5 * sum[2_n](t_j)\n",
    "        a[i+1] = a[i]                     # c6 * sum[2_n](t_j - 1)\n",
    "        i = i - 1                         # c7 * sum[2_n](t_j - 1)\n",
    "    a[i+1] = key                          # c8 * (n - 1)\n",
    "      \n",
    "print(f'After: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best, worst, and average case analysis\n",
    "\n",
    "So if I asked you how long an algorithm takes to run, you'd probably say, \"it depends on the input you give it.\" In this class we mostly consider the \"worse-case running time\", which is the longest running time for any input of size _n_. (There is also \"best-case\" and \"average-case\".)\n",
    "\n",
    "For insertion sort, what are the worst and best case inputs? The __best case__ input is a __sorted array__, because you __never have to move elements__, and the __worst case__ input is a __backwards sorted array__, like [5,4,3,2,1].\n",
    "\n",
    "In the __best__ case, t_j = 1 for all _j_, and the running time T(n) is a __linear__ function of _n_. In the __worst__ case, we must compare each element A[j] with each element in the entire sorted subarray A[1..j-1], so t_j = _j_ for all _j_. Substituting in sum[j=2,n](j) = (n(n+1))/2 - 1 and sum[j=2,n](j-1) = (n(n-1))/2 - 1, we get that T(n) is __quadratic__ _n_.\n",
    "\n",
    "__Average-case__ analysis __presupposes a probability distribution__ on inputs, but if we __assume all permutations of a given input array are equally likely__, then the __average__ case has __quadratic__ runtime. (We won't prove this here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 3.1__ Graphic examples of the theta, big-O, and lambda notations. In each part, the value of n0 shown is the minimum possible value; any greater value would also work.\n",
    "\n",
    "(a) theta-notation bounds a function to within constant factors. We write f(n) = theta(g(n)) if there exist positive constants n0, c1, and c2 such that at and to the right of n0, the value of f(n) always lies between c1_g(n) and c2_g(n) inclusive.\n",
    "\n",
    "(b) O-notation gives an upper bound for a function to within a constant factor. We write f(n) = O(g(n)) if there are positive constant n0 and c such that at and to the right of n0, the value of f(n) always lies on or below c_g(n).\n",
    "\n",
    "(c) lambda-notation gives a lower bound for a function to within a constant factor. We write f(n) = lambda(g(n)) if there are positive constants n0 and c such that at and to the right of n0, the value of f(n) always lies on or above c_g(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have heard runtime described in terms of big-O notation, where linear algorithms run in time O(n), quadratic algorithms run in time O(n^2), etc. Formally, big-O notation is a property of functions, and not necessarily algorithms. However, since runtimes of algorithms are expressed as functions of the size of the input, it is common to say an algorithm \"is O(n^2)\" when its runtime is in the set of functions known as O(n^2).\n",
    "\n",
    "__Definition:__ For a given function g(n), O(g(n)) is the set of functions f(n) where there exist c, n0 > 0 such that 0 <= f(n) <= c_g(n) for all n >= n0.\n",
    "\n",
    "Colloquially, we say a function f(n) \"is O(g(n))\" if f(n) is a subset of O(g(n)). Also, an algorithm runs in O(g(n)) if its runtime is in O(g(n)).\n",
    "\n",
    "One thing you may notice from this definition is that big-O time complexity is not nearly as important as poeple say it is. Some people spend a lot of effort trying to find algorithms that are O(n^2) instead of O(n^3), because they say those algorithms are faster. However, the algorithm with better asymptotic complexity might actually be slower in most practical circumstances.\n",
    "\n",
    "This is for two reasons.\n",
    "\n",
    "The first reason is _c_. Maybe your O(n^2) algorithm runs in <= 1000000n^2 for all n >= 1, whereas your O(n^3) algorithm runs in 2n^3 for n >= 1. Then the O(n^2) algorithm would only start beating the O(n^3) algorithm at large values of n.\n",
    "\n",
    "The second reason is n0. The big-O guarantee says nothing about the behaviour of the function when n < n0. Your algorithm could potentially take an extremely long time on small inputs and a relatively small time on large inputs, and the time complexity would be relatively small.\n",
    "\n",
    "For instance, right now I'm running some code to get the followers of users on Twitter. If the user has up to 100000 followers, I call the Twitter API to grab the list of followers, and the amount of time it takes scales linearly with the number of followers. However, if the user has more than 100000 followers, I give up and just return an empty list. This algorithm technically runs in O(1) time (as a function of the number of followers of the user), because big-O notation only describes the behaviour of an algorithm on large inputs.\n",
    "\n",
    "__Example:__ Any algorithm that runs in time T(n) = n^2 + 2n + 5 runs in O(n^2). This is because 2n + 5 <= n^2 for all n >= 4, so when n >= 4, we can write n^2 + 2n + 5 <= 2n^2, which means the equations are satisfied for c = 2 and n0 = 4.\n",
    "\n",
    "__Example:__ Any algorithm that runs in time T(N) = n^2 runs in O(n^2 + 2n + 5). This is because n^2 < n^2 + 2n + 5 for any nonnegative n, so c = 1 and n0 = 1 satisfy the constraints of the definition.\n",
    "\n",
    "__Example:__ The function f(n) = log(n) is O(n). To show this we can show that for n > 2, log(n) < n. First of all, we have log(2) = 1 < 2, so n - log(n) > 0 for n = 2. Second of all, we can take derivatives to find that n - log(n) increases for n >= 2 (because the derivative of it with respect to n is 1 - 1/n, which is always greater than 0 for n >= 2). So n > log(n) when n >= 2.\n",
    "\n",
    "(Note that technically you can't take the derivative of _f_ if _f_ is only defined over the integers, and not over the real numbers. But we can prove the same result by differentiating the extension of _f_ to the real numbers.)\n",
    "\n",
    "__Example:__ Any function that is O(n) is also O(n^2). Let f be a subset of O(n). Then there exists c, n0 > 0 such that f(n) <= cn for n >= n0. But for n >= 1, we have cn <= cn^2. So f(n) <= cn^2 for n >= max(n0, 1).\n",
    "\n",
    "__Definition:__ For a given function g(n), lambda(g(n)) is the set of functions f(n) where there exist c, n0 > 0 such that 0 <= c*g(n) <= f(n) for all n >= n0.\n",
    "\n",
    "__Example:__ No function that is O(n) can be lambda(n^2). Suppose f is a subset of O(n). Then there exists c, n0 > 0 such that f(n) <= cn for all n >= n0. However, in order for _f_ to be lambda(n^2), we would need to find c', n0' such that f(n) >= c'n^2 for all n >= n0'. This can't work, because for any fiven value of c' and n0', you can find an N > n0, n0' where cn < c'n^2, so f(n) cannot be simultaneously <= cN and >= cN^2.\n",
    "\n",
    "Note that a function can be both O(g(n)) and lambda(g(n)). In this case, you may want to use different values of c and n0 when you are proving the O case and the lambda case. If a function is both O(g(N)) and lambda(g(n)), we say it is theta(g(n)).\n",
    "\n",
    "(We can alternatively define theta(g(n)) as the set of functions f(n) where there exists c1, c2, n0 > 0 such that 0 <= c1*g(n) <= f(n) <= c2*g(n) for all n >= n0.)\n",
    "\n",
    "Note that if f(n) is a subset of O(g(n)), then g(n) is a subset of lambda(f(n)). So in our example, f(n) = n^2 + 2n + 5 is actually both O(n^2) and lambda(n^2), making it theta(n^2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
